# Zed Command System Exploration
#
# Tests discovering how Zed handles editor commands starting from zero knowledge.
# The agent doesn't know about "Actions", "GPUI", or any Zed-specific terminology.
# They just know this is an editor and want to understand its command system.

[scenario]
id = "zed-command-system"
name = "Understanding Zed Command Architecture"
repo = "zed"
difficulty = "hard"
description = "Explore how Zed implements its command system, starting with zero knowledge"

[task]
prompt = "Understand how keyboard shortcuts and commands work in this editor"
intent = "architectural_discovery"

[expected]
# These are validation targets, but the queries shouldn't assume knowledge of them
must_find_files = [
    "**/editor/src/actions.rs",
    "**/gpui/src/keymap.rs",
    "**/gpui/src/action.rs",
    "**/gpui/src/key_dispatch.rs",
    "**/editor/src/element.rs",
]
must_find_symbols = ["Action", "dispatch", "Keymap", "KeyBinding", "actions!", "DispatchTree", "register_action"]
noise_patterns = ["**/tests/**", "test_*", "Mock*", "*_test.rs", "**/fixtures/**"]

# Step 1: Natural question - no jargon
[[steps]]
query = "How do keyboard shortcuts trigger functionality in this editor?"
expected_results = 5
max_noise_ratio = 0.3
scope = "code"
expand_top = 4

# Step 2: Follow up - still no assumed knowledge
[[steps]]
query = "Where are these keyboard actions defined?"
depends_on_previous = true
expected_results = 4
scope = "code"
expand_top = 3

# Step 3: Drill into discovered concept using adaptive template
[[steps]]
query = "How is {{previous.symbol}} implemented?"
depends_on_previous = true
expected_results = 3
scope = "code"
expand_top = 3

# Step 4: Understand the dispatch mechanism
[[steps]]
query = "How does a keypress become an action execution?"
depends_on_previous = true
expected_results = 3
scope = "code"
context_ids = ["{{previous.id}}"]
expand_top = 2

[success]
min_discovery_score = 0.6
max_noise_ratio = 0.30
max_steps_to_core = 3
min_convergence_rate = 0.5
max_context_bloat = 0.35
min_file_diversity = 0.5

# LLM comprehension testing
[llm_judge]
min_comprehension_score = 0.5

[[llm_judge.comprehension_questions]]
question = "How are commands/actions represented in this editor's architecture?"
expected_concepts = ["Action", "trait", "actions!", "derive(Action)", "GPUI"]
wrong_concepts = ["Command pattern class", "event listeners", "Redux"]
weight = 1.5

[[llm_judge.comprehension_questions]]
question = "What is the flow from pressing a key to executing functionality?"
expected_concepts = ["DispatchTree", "KeyBinding", "Action", "on_action", "key_context"]
wrong_concepts = ["DOM events", "event bubbling"]
weight = 1.5

[[llm_judge.comprehension_questions]]
question = "How would you add a new keyboard shortcut for a custom action?"
expected_concepts = ["Action", "keymap JSON", "register_action", "actions!"]
wrong_concepts = ["config file only", "plugin"]
weight = 1.0
